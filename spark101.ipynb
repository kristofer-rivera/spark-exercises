{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27175180-c8a4-434c-a2f8-ba0dec11f341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/homebrew/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/23 15:12:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/05/23 15:12:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/05/23 15:12:30 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "import pydataset\n",
    "from pyspark.sql.functions import sum, mean, concat, lit, regexp_extract, regexp_replace, when\n",
    "from vega_datasets import data\n",
    "from pyspark.sql.functions import month, year, quarter\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78659011-391c-4192-8c1a-c0ea838daca1",
   "metadata": {},
   "source": [
    "## 1. Create a spark data frame that contains your favorite programming languages.\n",
    "- The name of the column should be language\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a492b8ba-f75e-48e8-90aa-c98d92517697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe\n",
    "df = spark.createDataFrame(pd.DataFrame({'language': ['Python', \n",
    "                                                      'SQL', \n",
    "                                                      'R', \n",
    "                                                      'C++', \n",
    "                                                      'Java',\n",
    "                                                      'Ruby']}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154786f3-04b7-444d-b387-f03bb14cfaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(language,StringType,true)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the schema\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111cbe10-6a09-425a-82b3-f6268c75acfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Output the shape\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19628353-a41d-4103-8865-1382fbe17ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|  Python|\n",
      "|     SQL|\n",
      "|       R|\n",
      "|     C++|\n",
      "|    Java|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the first five records in the dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f4f2a9-627d-49a4-92a6-d2290e7a4607",
   "metadata": {},
   "source": [
    "## 2. Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "**a. Create 1 column of output that contains a message like the one below:**\n",
    "\n",
    "The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "**For each vehicle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bd4f6b6-5826-49e3-9d1f-261c6d8e2b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = spark.createDataFrame(pydataset.data(\"mpg\"))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d28523-c12a-4850-8892-5169063558a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+\n",
      "|cylinder_description                                          |\n",
      "+--------------------------------------------------------------+\n",
      "|The 1999 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 6 cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 6 cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 6 cylinder engine.                     |\n",
      "|The 1999 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 1999 audi a6 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a6 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a6 quattro has a 8 cylinder engine.             |\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a 8 cylinder engine.|\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a 8 cylinder engine.|\n",
      "+--------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the column with the message\n",
    "df.select(\n",
    "    concat(\n",
    "        lit(\"The \"),\n",
    "        col(\"year\"),\n",
    "        lit(\" \"),\n",
    "        col(\"manufacturer\"),\n",
    "        lit(\" \"),\n",
    "        col(\"model\"),\n",
    "        lit(\" has a \"),\n",
    "        col(\"cyl\"),\n",
    "        lit(\" cylinder engine.\"),\n",
    "    ).alias(\"cylinder_description\")\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab878bd-92f8-48b1-9464-c68429b05a30",
   "metadata": {},
   "source": [
    "**b. Transform the trans column so that it only contains either manual or auto.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5186a840-0cef-496e-9410-e107bb0c8b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|     trans|transmission|\n",
      "+----------+------------+\n",
      "|  auto(l5)|        auto|\n",
      "|manual(m5)|      manual|\n",
      "|manual(m6)|      manual|\n",
      "|  auto(av)|        auto|\n",
      "|  auto(l5)|        auto|\n",
      "|manual(m5)|      manual|\n",
      "|  auto(av)|        auto|\n",
      "|manual(m5)|      manual|\n",
      "|  auto(l5)|        auto|\n",
      "|manual(m6)|      manual|\n",
      "|  auto(s6)|        auto|\n",
      "|  auto(l5)|        auto|\n",
      "|manual(m5)|      manual|\n",
      "|  auto(s6)|        auto|\n",
      "|manual(m6)|      manual|\n",
      "|  auto(l5)|        auto|\n",
      "|  auto(s6)|        auto|\n",
      "|  auto(s6)|        auto|\n",
      "|  auto(l4)|        auto|\n",
      "|  auto(l4)|        auto|\n",
      "+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('trans',regexp_replace('trans', r'\\(\\w+\\)$', '').alias('transmission')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89d3ccb-f88c-43ac-99af-2573f7f6ae73",
   "metadata": {},
   "source": [
    "## 3. Load the tips dataset as a spark dataframe.\n",
    "\n",
    "**a. What percentage of observations are smokers?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7db1d504-5c6c-45a7-a676-a3fdc5d309c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data set\n",
    "df = spark.createDataFrame(pydataset.data(\"tips\"))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9342d0f3-70b0-4c35-b3f4-5403d8c379cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------+\n",
      "|avg(CASE WHEN (smoker = Yes) THEN 1 ELSE 0 END)|\n",
      "+-----------------------------------------------+\n",
      "|                            0.38114754098360654|\n",
      "+-----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of smokers by creating a filtered subset and taking the mean\n",
    "smokers = when(df.smoker == 'Yes', 1).otherwise(0)\n",
    "df.select(mean(smokers)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6a6aee-2a40-4939-a02b-9ede968ac8e4",
   "metadata": {},
   "source": [
    "**b. Create a column that contains the tip percentage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2dd1b91-1173-4b31-81fc-d9a5650101a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|        tip_percent|\n",
      "+-------------------+\n",
      "|0.05944673337257211|\n",
      "|0.16054158607350097|\n",
      "|0.16658733936220846|\n",
      "| 0.1397804054054054|\n",
      "|0.14680764538430255|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tip_percent = (df.tip / df.total_bill).alias('tip_percent')\n",
    "df.select(tip_percent).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905f355f-7b84-4798-9f9c-9390f28e4d83",
   "metadata": {},
   "source": [
    "**c. Calculate the average tip percentage for each combination of sex and smoker.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab0c5a89-a1a0-47ac-9f4e-2623e0084cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------------------------------------+\n",
      "|   sex|smoker|avg((tip / total_bill) AS tip_percent)|\n",
      "+------+------+--------------------------------------+\n",
      "|  Male|    No|                    0.1606687151291298|\n",
      "|Female|    No|                    0.1569209707691836|\n",
      "|  Male|   Yes|                   0.15277117520248512|\n",
      "|Female|   Yes|                   0.18215035269941032|\n",
      "+------+------+--------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupby('sex', 'smoker').agg(mean(tip_percent)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcc1fde-24d6-42bd-9efc-62c043ab8383",
   "metadata": {},
   "source": [
    "## 4. Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "- Convert the temperatures to fahrenheit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0dc1147-d31d-4661-9374-f1c489edea11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data set\n",
    "df = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "df = spark.createDataFrame(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be099b9a-6084-4b37-b6d1-00f13e68d5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+------------------+--------+----+-------+\n",
      "|      date|precipitation|          temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+------------------+--------+----+-------+\n",
      "|2012-01-01|          0.0|55.040000000000006|    41.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|             51.08|   37.04| 4.5|   rain|\n",
      "|2012-01-03|          0.8|             53.06|   44.96| 2.3|   rain|\n",
      "|2012-01-04|         20.3|             53.96|   42.08| 4.7|   rain|\n",
      "|2012-01-05|          1.3|48.019999999999996|   37.04| 6.1|   rain|\n",
      "+----------+-------------+------------------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Converting temps to fahrenheit\n",
    "df = df.withColumn('temp_max', df.temp_max * (9/5) + 32)\n",
    "df = df.withColumn('temp_min', df.temp_min * (9/5) + 32)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e384d-55a4-4fff-a73f-3e5b0a1647f7",
   "metadata": {},
   "source": [
    "- Which month has the most rain, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "265ab2ca-07ea-4be7-9bd9-d4cf0275fc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|month|         avg_rain|\n",
      "+-----+-----------------+\n",
      "|   11|5.354166666666667|\n",
      "+-----+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(df.withColumn('month', month('date'))\n",
    "    .groupBy('month')\n",
    "    .agg(mean('precipitation').alias('avg_rain'))\n",
    "    .sort(desc('avg_rain'))\n",
    "    .show(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad9850-449d-4cd3-a12b-b39233896b9f",
   "metadata": {},
   "source": [
    "- Which year was the windiest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec3b1a50-681b-4bdb-9aef-b0f406a10496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|year|        total_wind|\n",
      "+----+------------------+\n",
      "|2013|1100.8000000000006|\n",
      "|2015|1153.3000000000002|\n",
      "|2014|1236.5000000000007|\n",
      "|2012|            1244.7|\n",
      "+----+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(df.withColumn(\"year\", year(\"date\"))\n",
    "    .groupBy(\"year\")\n",
    "    .agg(sum(\"wind\").alias(\"total_wind\"))\n",
    "    .sort(\"total_wind\")\n",
    "    .show()\n",
    ") # 2012 is windiest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b9ea38-ba79-4877-a6f9-e2b1945abfbe",
   "metadata": {},
   "source": [
    "- What is the most frequent type of weather in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20427b4b-c805-4a70-b196-88129d31399c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+------------------+------------------+----+-------+----+\n",
      "|      date|precipitation|          temp_max|          temp_min|wind|weather|year|\n",
      "+----------+-------------+------------------+------------------+----+-------+----+\n",
      "|2012-01-01|          0.0|55.040000000000006|              41.0| 4.7|drizzle|2012|\n",
      "|2012-01-02|         10.9|             51.08|             37.04| 4.5|   rain|2012|\n",
      "|2012-01-03|          0.8|             53.06|             44.96| 2.3|   rain|2012|\n",
      "|2012-01-04|         20.3|             53.96|             42.08| 4.7|   rain|2012|\n",
      "|2012-01-05|          1.3|48.019999999999996|             37.04| 6.1|   rain|2012|\n",
      "|2012-01-06|          2.5|             39.92|             35.96| 2.2|   rain|2012|\n",
      "|2012-01-07|          0.0|             44.96|             37.04| 2.3|   rain|2012|\n",
      "|2012-01-08|          0.0|              50.0|             37.04| 2.0|    sun|2012|\n",
      "|2012-01-09|          4.3|             48.92|              41.0| 3.4|   rain|2012|\n",
      "|2012-01-10|          1.0|42.980000000000004|             33.08| 3.4|   rain|2012|\n",
      "|2012-01-11|          0.0|42.980000000000004|             30.02| 5.1|    sun|2012|\n",
      "|2012-01-12|          0.0|42.980000000000004|             28.94| 1.9|    sun|2012|\n",
      "|2012-01-13|          0.0|              41.0|             26.96| 1.3|    sun|2012|\n",
      "|2012-01-14|          4.1|             39.92|             33.08| 5.3|   snow|2012|\n",
      "|2012-01-15|          5.3|             33.98|26.060000000000002| 3.2|   snow|2012|\n",
      "|2012-01-16|          2.5|             35.06|             26.96| 5.0|   snow|2012|\n",
      "|2012-01-17|          8.1|             37.94|              32.0| 5.6|   snow|2012|\n",
      "|2012-01-18|         19.8|              32.0|             26.96| 5.0|   snow|2012|\n",
      "|2012-01-19|         15.2|             30.02|             26.96| 1.6|   snow|2012|\n",
      "|2012-01-20|         13.5|             44.96|             30.02| 2.3|   snow|2012|\n",
      "+----------+-------------+------------------+------------------+----+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add year column to df\n",
    "df = df.withColumn(\"year\", year(\"date\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25e551e0-7796-4f37-8675-fd6a4b3ac9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|weather|n_days|\n",
      "+-------+------+\n",
      "|drizzle|    10|\n",
      "|   rain|    35|\n",
      "|    sun|    33|\n",
      "|   snow|     8|\n",
      "|    fog|    38|\n",
      "+-------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "january = df.filter(month('date') == '01').groupby('weather').count()\n",
    "january = january.withColumnRenamed('count', 'n_days')\n",
    "january.show()\n",
    "# Fog wins most frequent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5e6f63-b0cc-4340-90fa-593231353338",
   "metadata": {},
   "source": [
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e319b2dc-f000-42b4-b55b-73bf334b5cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|    avg(temp_max)|\n",
      "+-----------------+\n",
      "|65.37874999999998|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate high\n",
    "df_13_14 = df.filter(((df.year == 2013) | (df.year == 2014)) & (df.weather == 'sun'))\n",
    "df_13_14.select(mean('temp_max')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea216a35-2eb4-475c-a7b2-37d5f963f1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|    avg(temp_min)|\n",
      "+-----------------+\n",
      "|48.28913461538461|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate low\n",
    "df_13_14.select(mean('temp_min')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0710e8-2348-44c4-93a0-3ce763dc621f",
   "metadata": {},
   "source": [
    "- What percentage of days were rainy in q3 of 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e87a1910-6b4a-4967-ae44-cbf80cd56359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+------------------+--------+----+-------+----+-------+\n",
      "|      date|precipitation|          temp_max|temp_min|wind|weather|year|quarter|\n",
      "+----------+-------------+------------------+--------+----+-------+----+-------+\n",
      "|2012-01-01|          0.0|55.040000000000006|    41.0| 4.7|drizzle|2012|      1|\n",
      "|2012-01-02|         10.9|             51.08|   37.04| 4.5|   rain|2012|      1|\n",
      "|2012-01-03|          0.8|             53.06|   44.96| 2.3|   rain|2012|      1|\n",
      "|2012-01-04|         20.3|             53.96|   42.08| 4.7|   rain|2012|      1|\n",
      "|2012-01-05|          1.3|48.019999999999996|   37.04| 6.1|   rain|2012|      1|\n",
      "+----------+-------------+------------------+--------+----+-------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add quarter column to df\n",
    "df = df.withColumn('quarter', quarter('date'))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "069e14b4-29f1-4937-84cd-785205975114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-----------------+-----------------+----+-------+----+-------+\n",
      "|      date|precipitation|         temp_max|         temp_min|wind|weather|year|quarter|\n",
      "+----------+-------------+-----------------+-----------------+----+-------+----+-------+\n",
      "|2015-07-01|          0.0|89.96000000000001|            62.96| 4.3|    sun|2015|      3|\n",
      "|2015-07-02|          0.0|            93.02|64.03999999999999| 3.4|    sun|2015|      3|\n",
      "|2015-07-03|          0.0|            91.94|64.03999999999999| 2.6|    sun|2015|      3|\n",
      "|2015-07-04|          0.0|            91.94|             59.0| 2.9|    sun|2015|      3|\n",
      "|2015-07-05|          0.0|91.03999999999999|            62.06| 2.1|    sun|2015|      3|\n",
      "+----------+-------------+-----------------+-----------------+----+-------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subset the data with our paramaters\n",
    "rain_q3 = df.filter(expr('year == 2015 AND quarter == 3'))\n",
    "rain_q3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1975ab14-fc46-47b7-96f4-1052289c584d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021739130434782608"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the percentage of whole\n",
    "rain_q3.where(rain_q3.weather=='rain').count() / rain_q3.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8344052b-7d36-44ab-be44-e4d58b17bcc6",
   "metadata": {},
   "source": [
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e804553d-95e1-4c74-a9be-274587af992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('had_precip', when((df.precipitation > 0), 1)\n",
    "                                    .otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8ecb850-03b7-4106-aed7-e25bdacdc1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|year|    avg(had_precip)|\n",
      "+----+-------------------+\n",
      "|2012|0.48360655737704916|\n",
      "|2013|0.41643835616438357|\n",
      "|2014|  0.410958904109589|\n",
      "|2015|0.39452054794520547|\n",
      "+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('year').agg(mean('had_precip')).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python397jvsc74a57bd038cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
